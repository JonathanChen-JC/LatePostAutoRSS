# GPT-5 有了雏形；OpenAI 和 Manus 研发 Agent 的经验；中国大公司扩大算力投资丨 AI 月报

- **发布日期**: 03月08日 21:03
- **作者**: 贺乾明
- **原文链接**: https://www.latepost.com/news/dj_detail?id=2840

---

> 2025 年 2 月的 AI 月报，你会看到：

> 硅谷巨头的新共识：推理能力是大模型的一部分

> OpenAI 和 Manus 的 Agent 开发经验

> DeepSeek 推动中国大公司加大算力投入，阿里、字节两家加起来，今年就超过 2000 亿

> 3 家售价过亿的 AI 公司和 23 家获得超过 5000 万美元融资的 AI 公司

> OpenAI 时薪 100 美元招专家生产数据提高模型能力

这一期月报中，我们开始邀请研究者、创业者和投资人提供一手视角的对每月 AI 趋势和标志性事件的评述和洞察。

晚点 AI 月报，每月选取最值得你知道的 AI 信号。

以下是我们第 4 期 AI 月报，欢迎大家在留言区补充我们没有提到的重要趋势。

技术丨GPT-5 雏形出现，行业新共识诞生

DeepSeek 带来的冲击波继续扩散，全球大模型公司陷入混战：不论是马斯克用超过 10 万张 GPU 训练的 Grok 3，还是 OpenAI 可能投入 10 亿美元训练的 GPT-4.5，或是 Anthropic 融合推理（reasoning）能力的最新模型 Claude 3.7 Sonnet，都没有带动大模型能力大幅提升。

发布 GPT-4.5 前，OpenAI 给出模型能力继续提升的路径：把基础模型（如 GPT-4.5）和推理模型 o3 融合在一起发布 GPT-5，有点像 Claude 3.7 的做法。

这是大模型行业头部公司的新共识。从 OpenAI 跳槽到 Google 的开发者关系负责人洛根·基尔帕特里克（Logan Kilpatrick）说：“这一直是 Gemini 的计划，确保推理能力是基础模型的一部分，而不是一个支线任务，因此开发了 Gemini 2.0 Flash Thinking。”

OpenAI 认为，无监督学习（unsupervised learning）和推理（reasoning），代表智能的两个轴 [1]：

“我们发现这两种范式互补，并认为它们之间存在反馈循环。”OpenAI 首席研究官陈信翰（Mark Chen）参加播客节目时说，“知识是推理的基础。模型不能从零开始学习推理。”

但这类模型在投入使用时会面临麻烦：不是所有问题，都需要用领先模型解决，比如总结一段文本，能在手机上部署的模型没比 GPT-4o 差多少。

OpenAI 准备做一个自动识别用户提出的问题、判断用什么模式回答问题的系统，但会给免费用户和付费用户分层 [2]：

斯坦福大学计算机科学助理教授珀西·梁（Percy Liang）在社交媒体上评论 [3]：

> 从产品的角度来看，这样做非常合理。然而，从研究人员和开发人员的角度来看，将所有内容都封装起来，会让我们越来越难理解底层的运作机制。我们过去拥有一个对应自回归概率模型的端点（endpoint），能直接处理 token；但现在，我们将只有一个神秘的 “黑盒子”。

一位中国大模型公司研究员说：

> 这也是我们正在做的方向。（大模型公司）基本最后都会走 system1（GPT-4o 类模型） 跟 system2 （o1 或 R1 类模型）结合的路线。现在大家都是摸着石头过河。

应用丨Deep Research 成为热门 Agent

知名分析师的使用经验：每月花 200 美元雇了一名员工

Deep Research 成为大模型 Agent 时代的热门应用。OpenAI 介绍，只需提供一个提示，它就会调用模型查找、分析和综合数百个在线资源（搜索、解释和分析互联网上大量的文本、图像和 PDF 文件，根据遇到的信息灵活调整策略），生成一份研究员水平报告。

知名分析师本·汤普森（Ben Thompson）[4] 用 Deep Research 写苹果财报分析后评论：“感觉有点像 AGI”“像是每月花 200 美元的惊人低价雇了一名员工”。他分享了理由和使用技巧：

OpenAI 开发 Deep Research 的经验：强化学习是关键

去年 12 月，Google 就发布基于 Gemini 1.5 模型的 Deep Research 功能；OpenAI 刚推出一天，开源社区 HuggingFace 就提供了开源复现版本；之后不久，大模型搜索应用 Perplexity 推出类似的功能。

但最受关注的还是 OpenAI 版本的 Deep Research——哪怕每个月要付 200 美元才能自由使用。

“归根结底，在于如何开发模型、是否努力构建数据集。”OpenAI 负责开发 Deep Research 的乔什·托宾（Josh Tobin）说。

他和另一位 Deep Research 的开发者伊萨·福尔福德（Isa Fulford）参加红杉资本的播客节目，分享了 OpenAI 开发 Deep Research 的经验 [5]：

本期月报发布前，中国创业公司发布的 Agent 应用 Manus 引发关注。Manus AI 的联合创始人、首席科学家季逸超分享了他们开发 Agent 的经验：

> 我们坚信并践行 less structure，more intelligence 的哲学：当你的数据足够优质、模型足够智能、架构足够灵活、工程足够扎实，那么 computer use、deep research、coding agent 等概念就从产品特性变为了自然涌现的能力。技术之外，回归第一性原理也让我们对产品形态有了全新的思考：

> AI 浏览器不是在浏览器里加 AI，而是做给 AI 用的浏览器；AI 搜索不是从索引召回再总结，而是让 AI 以用户的权限去获取信息；操作 GUI 不是抢夺用户设备的控制权，而是让 AI 有自己的虚拟机；编写代码不是最终目的，而是解决各种问题的通用媒介；生成网站的难点不是搭建框架，而是让内容言之有物；Attention 不是 all you need，解放用户的 attention 才能重新定义 DAU。

投资了多家大模型创业公司的真格基金管理合伙人戴雨森说：

> 模型的推理能力、编程能力、工具使用能力提升，解锁了 Agent 。没有推理能力，无法很好地计划，无法消化海量信息。没有编程能力，无法用 Python 等工具处理文件、数据等任务。而工具方面，浏览器只是一个最基本的工具，以后还会有其他的软件。

> 这些能力的共同进步，到达临界点后，能够把一个 Agent 产品做出来。当然，这些能力还有很多的提升空间，所以现在还是非常早期的阶段。再过半个月、半年、一年，产品能力可能又会变得不一样。

> 以前人类用的所有工具都需要 Attention，即需要人给予注意力，关照工作的进度，“ Attention is all you need；而 AI 技术进步，大家会做出来不需要 Attention 就能主动完成复杂任务的工具，这会解锁人类的潜能。

基建｜DeepSeek 成为算力投资关键变量

DeepSeek 推动中国公司扩大算力投入，阿里计划三年投 3800 亿元

DeepSeek 让大量原本处于观望状态的行业、公司接受大模型，带动中国的算力投资：

DeepSeek 模型的特点是低成本、高效率，但大规模投入使用仍需要大量的算力，主要有两个因素：

已经投资了两年的微软说：算力中心存在过度建设

微软上个月叫停在建的威斯康星州数据中心后，2 月又取消一批美国数据中心的租约。一个可能的因素是，微软不再是 OpenAI 唯一算力供应商，OpenAI 正在加大甲骨文算力的用量。

微软 CEO 萨提亚·纳德拉（Satya Nadella）在一档播客节目说 [6]：（算力）会有过度建设，微软 “非常高兴在 2027 年、2028 年租赁大量的算力”，因为 “建设的唯一结果是价格会下降。”

英伟达陷入震荡，反弹的股价又跌了回去

英伟达的股价在 2 月走过一个倒 U 型曲线，前 20 天上涨 17%，基本回到 DeepSeek 冲击前的水平；随后又开始下跌，到 3 月初降了近 20%。

投融资丨3 家 AI 公司卖了超 1 亿美元，23 家 AI 公司融资超过 5000 万美元

3 笔金额超过 1 亿美元的并购案，有一笔投资人回报丰厚，有一笔投资人亏损：

基础模型：两家 OpenAI 系公司寻求高估值融资

2 月，我们只关注到一家研发基础模型的公司宣布完成超 5000 万美元融资：

但还有两家 OpenAI 系基础模型公司正在寻求高估值融资，尽管它们没有产品、没有收入：

基础设施：英伟达是大赢家；还有两家量子计算公司融资

英伟达投资的 GPU 算力租赁公司 CoreWeave 在近期递交招股书，预期集资 40 亿美元，估值约 350 亿美元。2 月还有英伟达支持的另外两家 GPU 算力租赁公司宣布获得大额融资：

其他获得超过 5000 万美元的融资的 AI 基础设施公司有：

2 月还有两家量子计算公司获得超过 5000 万美元融资：

应用：主要是前 ChatGPT 时代成立的公司拿到融资

跟前两个月类似，获得超过 5000 万美元融资的 AI 应用公司，基本都在 2023 年之前成立，2023 年及之后成立的公司有两家：

其他共识都瞄准特定行业或应用场景，大模型到来前就积累了大量客户：

![图片](https://p3-sign.toutiaoimg.com/tos-cn-i-6w9my0ksvp/20d1d33fb99846ccb3560c6990618cb9~tplv-tt-origin-web:gif.jpeg?_iz=58558&from=article.pc_detail&lk3s=953192f4&x-expires=1742044729&x-signature=U8I7SL%2BQ1JtrjaZ%2Fz8%2BQNFC8iPI%3D)

Apptronik 开发的人形机器人。

最后丨OpenAI 提升模型能力的一个方法：时薪 100 美元找人写数据

大模型的能力无法沿着过往 Scaling Laws 提升的桎梏，是领先的大模型已经吞掉几乎所有公开、优质的数据。

为了解决这个问题，大模型公司尝试用 AI 生成数据。比如 DeepSeek 训练 R1 模型时，就训练了 “专家模型” 生成数学、编程等领域的问题。OpenAI 也在利用 o 系列模型生成用于训练 GPT-4.5 的数据。

也有公司花重金雇专家撰写数据。2 月，有媒体报道了 OpenAI 用人生产数据的情况 [7]：

在 AI 领域存在一个定律：数据质量决定模型能力。模型算法随着开源和人才流动在行业中扩散，数据在竞争中的重要程度越来越高。

“真正在意软件的人，应该自己造硬件。” 计算机科学家艾伦·凯（Alan Kay）的这句名言，在大模型时代也有了新的变体：真正在意 AI 的人，应该重视数据。

[1] OpenAI 分享如何提升大模型能力

https://openai.com/index/introducing-gpt-4-5/

[2] 阿尔特曼谈论 GPT-5 的规划

https://x.com/sama/status/1889755723078443244

[3] 斯坦福大学计算机科学助理教授珀西·梁评论 GPT-5 规划

https://x.com/percyliang/status/1890107330320347623

[4] 分析师本·汤普森使用 Deep Research 的体验

https://stratechery.com/2025/deep-research-and-knowledge-value/

[5]OpenAI 研究者分享开发 Deep Research 的经验

https://www.sequoiacap.com/podcast/training-data-deep-research/

[6] 微软 CEO 纳德拉分享谈论大模型基建：

https://www.dwarkeshpatel.com/p/satya-nadella

[7]The Information 报道 OpenAI 雇专家写数据

https://www.theinformation.com/articles/will-deepseek-hurt-scale-ais-business-model?rc=chhbyg

题图来源：AI 生成。
